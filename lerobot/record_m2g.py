#!/usr/bin/env python3
# Copyright 2024 The HuggingFace Inc. team. All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
'''
cd ~/vla/src/pyorbbecsdk
export PYTHONPATH=$PYTHONPATH:$(pwd)/install/lib/
sudo bash ./scripts/install_udev_rules.sh
sudo udevadm control --reload-rules
sudo udevadm trigger
cd /home/hpx/peter_ws/m2g_lerobot/lerobot
'''

"""
Records a dataset. Actions for the robot can be either generated by teleoperation or by a policy.

Example:

```shell
python -m lerobot.record \
    --robot.type=so100_follower \
    --robot.port=/dev/tty.usbmodem58760431541 \
    --robot.cameras="{laptop: {type: opencv, camera_index: 0, width: 640, height: 480}}" \
    --robot.id=black \
    --dataset.repo_id=aliberts/record-test \
    --dataset.num_episodes=2 \
    --dataset.single_task="Grab the cube" \
    # <- Teleop optional if you want to teleoperate to record or in between episodes with a policy \
    # --teleop.type=so100_leader \
    # --teleop.port=/dev/tty.usbmodem58760431551 \
    # --teleop.id=blue \
    # <- Policy optional if you want to record with a policy \
    # --policy.path=${HF_USER}/my_policy \

python -m lerobot.record  --srobot.type=koch_follower  --srobot.port=/ttyUSB0    --teleop.type=koch_leader   --teleop.port=/ttyUSB1  
--dataset.repo_id=hpx/cube1  --dataset.root=/media/hpx/newMemery/datasets/cube8  --dataset.push_to_hub=False   --dataset.num_episodes=100  
--dataset.single_task="Grab the toy and put it in the box"
```
"""

# import debugpy
# debugpy.listen(("0.0.0.0", 2457))  # 监听5678端口
# print("Waiting for debugger attach...")
# debugpy.wait_for_client()

######这个文件负责整个记录流程。相当于导演编剧
import ast
import logging

import socket

import time

import draccus
import numpy as np
import rerun as rr

from dataclasses import asdict, dataclass
from pathlib import Path
from pprint import pformat


from pytransform3d import rotations
from rtde_control import RTDEControlInterface
from rtde_receive import RTDEReceiveInterface

from dex_retargeting.retargeting_config import RetargetingConfig
from constants_vuer import tip_indices
from lerobot.common.robots import (
    Robot,
    RobotConfig,
    koch_follower,
    make_robot_from_config,
    so100_follower,
    so101_follower,
)

from lerobot.common.robots.ur5e_hand import UR5eHand
from lerobot.common.teleoperators import (
    Teleoperator,
    TeleoperatorConfig,
    koch_leader,
    make_teleoperator_from_config,
    so100_leader,
    so101_leader,
    VR_leader,
)
from lerobot.common.utils.control_utils import (
    init_keyboard_listener,
    is_headless,
    predict_action,
    sanity_check_dataset_name,
    sanity_check_dataset_robot_compatibility,
)
from lerobot.common.utils.robot_utils import busy_wait
from lerobot.common.utils.utils import (
    get_safe_torch_device,
    init_logging,
    log_say,
)
from lerobot.common.utils.visualization_utils import _init_rerun

from lerobot.common.datasets.image_writer import safe_stop_image_writer
from lerobot.common.datasets.lerobot_dataset import LeRobotDataset
from lerobot.common.datasets.utils import build_dataset_frame, hw_to_dataset_features

from lerobot.common.policies.factory import make_policy
from lerobot.common.policies.pretrained import PreTrainedPolicy
from lerobot.configs import parser
from lerobot.configs.policies import PreTrainedConfig

def is_port_in_use(ip, port):
    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    s.settimeout(1)
    try:
        result = s.connect_ex((ip, port))
        s.close()
        # 0 表示端口已被占用（有服务监听），111/10061等表示未监听
        return result == 0
    except Exception as e:
        print(f"Port check error: {e}")
        return False
        
@dataclass
class DatasetRecordConfig:
    # Dataset identifier. By convention it should match '{hf_username}/{dataset_name}' (e.g. `lerobot/test`).
    repo_id: str
    # A short but accurate description of the task performed during the recording (e.g. "Pick the Lego block and drop it in the box on the right.")
    single_task: str
    # Root directory where the dataset will be stored (e.g. 'dataset/path').
    root: str | Path | None = None
    # Limit the frames per second.
    fps: int = 30
    # Number of seconds for data recording for each episode.
    episode_time_s: int | float = 60
    # Number of seconds for resetting the environment after each episode.
    reset_time_s: int | float = 60
    # Number of episodes to record.
    num_episodes: int = 20
    # Encode frames in the dataset into video
    video: bool = True
    # Upload dataset to Hugging Face hub.
    push_to_hub: bool = True
    # Upload on private repository on the Hugging Face hub.
    private: bool = False
    # Add tags to your dataset on the hub.
    tags: list[str] | None = None
    # Number of subprocesses handling the saving of frames as PNG. Set to 0 to use threads only;
    # set to ≥1 to use subprocesses, each using threads to write images. The best number of processes
    # and threads depends on your system. We recommend 4 threads per camera with 0 processes.
    # If fps is unstable, adjust the thread count. If still unstable, try using 1 or more subprocesses.
    num_image_writer_processes: int = 0
    # Number of threads writing the frames as png images on disk, per camera.
    # Too many threads might cause unstable teleoperation fps due to main thread being blocked.
    # Not enough threads might cause low camera fps.
    num_image_writer_threads_per_camera: int = 4

    def __post_init__(self):
        if self.single_task is None:
            raise ValueError("You need to provide a task as argument in `single_task`.")


@dataclass
class RecordConfig:
    srobot: RobotConfig
    #robot = make_robot_from_config(cfg.robot)
    #robot: Optional[RobotConfig] = None
    dataset: DatasetRecordConfig
    # Whether to control the robot with a teleoperator
    teleop: TeleoperatorConfig | None = None
    # Whether to control the robot with a policy
    policy: PreTrainedConfig | None = None
    # Display all cameras on screen
    display_data: bool = False
    # Use vocal synthesis to read events.
    play_sounds: bool = True
    # Resume recording on an existing dataset.
    resume: bool = False

    auto_mode: bool = False #### 自动数据收集。
    force: int = 100  # 手部力传感器的初始力值
    grasp_pose: list[int] = None  # 手指抓取时的初始角度
    down_height: float = 0.13  # 初始下降高度

    def __post_init__(self):
        # HACK: We parse again the cli args here to get the pretrained path if there was one.
        policy_path = parser.get_path_arg("policy")
        if policy_path:
            cli_overrides = parser.get_cli_overrides("policy")
            self.policy = PreTrainedConfig.from_pretrained(policy_path, cli_overrides=cli_overrides)
            self.policy.pretrained_path = policy_path

        if self.teleop is None and self.policy is None:
            raise ValueError("Choose a policy, a teleoperator or both to control the robot")

    @classmethod
    def __get_path_fields__(cls) -> list[str]:
        """This enables the parser to load config from the policy using `--policy.path=local/dir`"""
        return ["policy"]


@safe_stop_image_writer
def record_loop(
    robot: Robot,
    events: dict,
    fps: int,
    dataset: LeRobotDataset | None = None,
    teleop: Teleoperator | None = None,
    policy: PreTrainedPolicy | None = None,
    control_time_s: int | None = None,
    single_task: str | None = None,
    display_data: bool = False,
):
    if dataset is not None and dataset.fps != fps:
        raise ValueError(f"The dataset fps should be equal to requested fps ({dataset.fps} != {fps}).")

    timestamp = 0
    start_episode_t = time.perf_counter()
    while timestamp < control_time_s:
        start_loop_t = time.perf_counter()

        if events["exit_early"]:
            events["exit_early"] = False
            break
        observation = robot.get_observation()
        if policy is not None or dataset is not None:
            observation_frame = build_dataset_frame(dataset.features, observation, prefix="observation")

        if policy is not None:
            action_values = predict_action(
                observation_frame,
                policy,
                get_safe_torch_device(policy.config.device),
                policy.config.use_amp,
                task=single_task,
                robot_type=robot.robot_type,
            )
            action = {key: action_values[i].item() for i, key in enumerate(robot.action_features)}
        elif policy is None:
            action = robot.get_action(events)
            old_control = events["control"]
            if action is None:
                logging.info("Teleoperator returned None action, skipping this loop iteration.")
                continue
        else:
            logging.info(
                "No policy or teleoperator provided, skipping action generation."
                "This is likely to happen when resetting the environment without a teleop device."
                "The robot won't be at its rest position at the start of the next episode."
            )
            continue

        # Action can eventually be clipped using `max_relative_target`,
        # so action actually sent is saved in the dataset.
        sent_action = robot.send_action(action)
        if dataset is not None:
            action_frame = build_dataset_frame(dataset.features, sent_action, prefix="action")
            frame = {**observation_frame, **action_frame}
            dataset.add_frame(frame, task=single_task)
        if display_data:
            for obs, val in observation.items():
                if isinstance(val, float):
                    rr.log(f"observation.{obs}", rr.Scalars(val))
                elif isinstance(val, np.ndarray):
                    rr.log(f"observation.{obs}", rr.Image(val), static=True)
            for act, val in action.items():
                if isinstance(val, float):
                    rr.log(f"action.{act}", rr.Scalars(val))

        dt_s = time.perf_counter() - start_loop_t
        busy_wait(1 / fps - dt_s)

        timestamp = time.perf_counter() - start_episode_t


@parser.wrap()
def record(cfg: RecordConfig,robot: UR5eHand,listener, events) -> LeRobotDataset:
    init_logging()
    logging.info(pformat(asdict(cfg)))
    if cfg.display_data:
        _init_rerun(session_name="recording")


    # ===== 新增：自动模式启动 =====
    if cfg.auto_mode:
        events["start_record"] = True
        events["auto_mode"] = True
        
    # ============================

    teleop = None
    action_features = hw_to_dataset_features(robot.action_features, "action", cfg.dataset.video)
    obs_features = hw_to_dataset_features(robot.observation_features, "observation", cfg.dataset.video)
    dataset_features = {**action_features, **obs_features}

    if cfg.resume:
        dataset = LeRobotDataset(
            cfg.dataset.repo_id,
            root=cfg.dataset.root,
        )

        if hasattr(robot, "cameras") and len(robot.cameras) > 0:
            dataset.start_image_writer(
                num_processes=cfg.dataset.num_image_writer_processes,
                num_threads=cfg.dataset.num_image_writer_threads_per_camera * len(robot.cameras),
            )
        sanity_check_dataset_robot_compatibility(dataset, robot, cfg.dataset.fps, dataset_features)
    else:
        # Create empty dataset or load existing saved episodes
        sanity_check_dataset_name(cfg.dataset.repo_id, cfg.policy)
        dataset = LeRobotDataset.create(
            cfg.dataset.repo_id,
            cfg.dataset.fps,
            root=cfg.dataset.root,
            robot_type=robot.name,
            features=dataset_features,
            use_videos=cfg.dataset.video,
            image_writer_processes=cfg.dataset.num_image_writer_processes,
            image_writer_threads=cfg.dataset.num_image_writer_threads_per_camera * len(robot.cameras),
        )

    # Load pretrained policy
    policy = None if cfg.policy is None else make_policy(cfg.policy, ds_meta=dataset.meta)

    robot.connect()

    recorded_episodes = 0

    # while 还没录完:
    # ├─ 调用 record_loop()         ← 正式采集一个 episode
    # │
    # ├─ if 还没采完 or 需要重录:    ← 判断是否 reset
    # │    ├─ 手动 reset 环境
    # │    └─ 再次调用 record_loop() ← reset 时间（不保存数据）
    # │
    # ├─ if 需要重录当前 episode:    ← 用户主动触发事件
    # │    ├─ 清空当前 buffer
    # │    └─ continue 回到 while 起点
    # │
    # └─ 正常保存 episode，计数 +1
    wait_time = 3
    while recorded_episodes < cfg.dataset.num_episodes and not events["stop_recording"]:
        log_say(f"Recording episode {dataset.num_episodes}", cfg.play_sounds)
        print("##########################################")
        print(f"[INFO] 正在开始录制 Episode {recorded_episodes + 1}/{cfg.dataset.num_episodes} ...")
        print("##########################################")

        ###给一个准备时间
        print(f"请准备好，{wait_time}秒后开始录制...")
        for i in range(wait_time, 0, -1):
            print(f"{i}秒")
            time.sleep(1)
        print("开始录制...")

        record_loop(
            robot=robot,
            events=events,
            fps=cfg.dataset.fps,
            teleop=teleop,
            policy=policy,
            dataset=dataset,
            control_time_s=cfg.dataset.episode_time_s,
            single_task=cfg.dataset.single_task,
            display_data=cfg.display_data,
        )

        # Execute a few seconds without recording to give time to manually reset the environment
        # Skip reset for the last episode to be recorded

        # if not events["stop_recording"] and (
        #     (recorded_episodes < cfg.dataset.num_episodes - 1) or events["rerecord_episode"]
        # ):
        if (not events["stop_recording"]) and (not events.get("auto_mode", False)) and (
            (recorded_episodes < cfg.dataset.num_episodes - 1) or events["rerecord_episode"]
        ):
            log_say("Reset the environment", cfg.play_sounds)
            events["control"] = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]

            joint_pos = robot.init_arm_joint

            robot.robot1.moveJ(joint_pos, 0.3, 0.5, False)
            record_loop(
                robot=robot,
                events=events,
                fps=cfg.dataset.fps,
                teleop=teleop,
                control_time_s=cfg.dataset.reset_time_s,
                single_task=cfg.dataset.single_task,
                display_data=cfg.display_data,
            )

        if events["rerecord_episode"]:
            log_say("Re-record episode", cfg.play_sounds)
            events["rerecord_episode"] = False
            events["exit_early"] = False
            dataset.clear_episode_buffer()
            continue

        if cfg.auto_mode:
            print("[INFO] 自动模式复位到初始姿态以消除误差")
            robot.robot1.moveJ(robot.init_arm_joint, 0.3, 0.5, False)
            time.sleep(1)

        dataset.save_episode()
        recorded_episodes += 1

    log_say("Stop recording", cfg.play_sounds, blocking=True)

    robot.hand.close()
    robot.disconnect()
    if teleop is not None:
        teleop.disconnect()

    if not is_headless() and listener is not None:
        listener.stop()

    log_say("Exiting", cfg.play_sounds)
    return dataset


if __name__ == "__main__":

    cfg = draccus.parse(config_class=RecordConfig)

    #############init_arm_joint###################
    # For a cup
    init_arm_joint = [-1.2074930475337116, -1.5226414808791908, -1.6494769486957281, -3.455183150582767, -1.297550940555798, -3.031452639979724]
    ###
    # For a cube height
    mid_joint = [-1.23796254793276, -1.644548078576559, -1.5001659393310538, -3.5, -1.377956692372459, -2.8083470503436505]
    #############init force#######################
    hard_force = 150
    soft_force = 90

    grasp_pose = cfg.grasp_pose if cfg.grasp_pose is not None else [400, 400, 400, 400, 700, 0]
    if isinstance(cfg.grasp_pose, str):
        grasp_pose = ast.literal_eval(cfg.grasp_pose)
    else:
        grasp_pose = cfg.grasp_pose if cfg.grasp_pose is not None else [400, 400, 400, 400, 700, 0]

    # # 选择关节
    # if cfg.tall_flag:
    #     init_arm_joint = tall_joint
    # else:
    #     init_arm_joint = mid_joint

    # # 选择手部力
    # if cfg.soft_flag:
    #     init_hand_force = soft_force
    # else:
    #     init_hand_force = hard_force
    
    if isinstance(cfg.force, str):
        init_hand_force = ast.literal_eval(cfg.force)
    else:
        init_hand_force = cfg.force if cfg.force is not None else 100  # 默认手部力传感器的初始力值

    init_hand_force_list = [init_hand_force] * 6

    init_hand_speed = 500
    init_hand_speed_list = [init_hand_speed] * 6

    if isinstance(cfg.down_height, str):
        init_down_height = ast.literal_eval(cfg.down_height)
    else:
        init_down_height = cfg.down_height if cfg.down_height is not None else 0.13

    arm_hand = UR5eHand(
        robot_ip="192.168.31.2", 
        hand_ip="192.168.11.210",
        hand_port=6000,
        init_force_values=init_hand_force_list,
        init_speed_values=init_hand_speed_list,
        init_arm_joint=init_arm_joint,
        init_grasp_pose=grasp_pose,  # 手指抓取时的初始角度
        init_down_height=init_down_height,  # 初始下降高度
    )
    listener, events = init_keyboard_listener()

    # hand = arm_hand.hand

    arm_hand.robot1.moveJ(arm_hand.init_arm_joint, 0.3, 0.5, False)
    time.sleep(2)  # 等待机器人到达初始位置

    # 自动模式：直接开启
    if cfg.auto_mode:
        events["start_record"] = True
        events["auto_mode"] = True
        start_flag = 2
    else:
        start_flag = 0

    try:
        while True:
            if events["stop_recording"]:
                break
            if events["restart_arm"]:
                print("机器人已重置！")
                # 重置机器人到初始位置
                joint_pos, tcp_pose = arm_hand.read()
                print(f"当前关节角度: {joint_pos}")
                print(f"当前TCP位姿: {tcp_pose}")
                arm_pose = tcp_pose.copy()
                arm_pose[2] -= 0.2
            
            # 手动或自动模式都可以进入录制
            if (events["start_record"] or events.get("auto_mode", False)) and start_flag == 0:
                start_flag = 1

            if start_flag == 0:
                joint_pos, tcp_pose = arm_hand.read()
                print(f"当前关节角度: {joint_pos}")
                print(f"当前TCP位姿: {tcp_pose}")
            elif start_flag == 1:
                time.sleep(2)  # 等待一段时间以确保数据稳定
                start_flag = 2
            elif start_flag == 2:

                ######  用来记录
                record(robot = arm_hand,listener = listener, events=events)
                ######  用来记录

                # ####### 用来测试
                # action = arm_hand.get_action(events)
                # tcp_targets = [action[f"tcp_{i+1}.pos"] for i in range(6)]
                # joint_targets = [action[f"joint_{i+1}.pos"] for i in range(6)]
                # velocity = 0.2
                # acceleration = 0.3
                # hands_action_angle = [action[f"hand_{i+1}.pos"] for i in range(6)]
                # hand_data = arm_hand.hand.read_force_angle_tactile()
                # hand_force = hand_data["forces"]
                # hand_angle = hand_data["angles"]
                # hand_tactile = hand_data["tactile"]
                # print(f"手部力传感器数据: {hand_force}")
                # print(f"手部角度传感器数据: {hand_angle}")
                # print(f"手部触觉传感器数据: {hand_tactile}")
                # print(f"ARM的tcp数据:{tcp_targets}")
                # print(f"ARM的joint数据:{joint_targets}")
                # arm_hand.robot1.moveL(tcp_targets, velocity, acceleration, False)
                # # hand_control(ser,hands)
                # arm_hand.hand.set_hand_angle(hands_action_angle)
                # ####### 用来测试

    except KeyboardInterrupt:
        # 退出时释放资源
        exit(0)
